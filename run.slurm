#!/bin/bash -l

##############################
#       Job blueprint        #
##############################

# Give your job a name, so you can recognize it in the queue overview
#SBATCH --job-name=sgi_drop

# Remove one # to uncommment
#SBATCH --output=slurm_output/%x-%j.txt

# Define, how many nodes you need. Here, we ask for 1 node.
#SBATCH -N 1 #nodes
#SBATCH -n 1 #tasks
#SBATCH --cpus-per-task=2
#SBATCH --mem=20G
#SBATCH --time=3-23:59:00   
#SBATCH --gres=gpu:1 

# Turn on mail notification. There are many possible self-explaining values:
# NONE, BEGIN, END, FAIL, ALL (including all aforementioned)
# For more values, check "man sbatch"
#SBATCH --mail-type=NONE
# Remember to set your email address here instead of nobody
#SBATCH --mail-user=jtuyls@cs.princeton.edu


# Define and create a unique scratch directory for this job
#tag="transformer";
#OUT_DIRECTORY='output/'${tag}
#mkdir ${OUT_DIRECTORY};

# Submit jobs.
version=4

module purge
eval "$(conda shell.bash hook)"
conda activate sgi
 
./scripts/experiments/sgim_pretrain.sh ${1} ${2}

wait; #Make sure to wait till all the runs have completed.

# Finish the script
exit 0

